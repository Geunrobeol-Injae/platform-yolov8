# Ultralytics YOLO ðŸš€, GPL-3.0 license

import hydra
import torch
import argparse
import time
from pathlib import Path

import cv2
import torch
import torch.backends.cudnn as cudnn
from numpy import random
from ultralytics.yolo.engine.predictor import BasePredictor
from ultralytics.yolo.utils import DEFAULT_CONFIG, ROOT, ops
from ultralytics.yolo.utils.checks import check_imgsz
from ultralytics.yolo.utils.plotting import Annotator, colors, save_one_box

import cv2
from deep_sort_pytorch.utils.parser import get_config
from deep_sort_pytorch.deep_sort import DeepSort
from collections import deque
import numpy as np

palette = (2 ** 11 - 1, 2 ** 15 - 1, 2 ** 20 - 1)  # ìƒ‰ìƒ ì„ ì •
data_deque = {}

deepsort = None

"""
1. count(founded_classes, im0)
- OpenCV ë¼ì´ë¸ŒëŸ¬ë¦¬ì˜ í•¨ìˆ˜ë“¤ì„ ì‚¬ìš©í•˜ì—¬ ì´ë¯¸ì§€ im0ì— ì—¬ëŸ¬ ì‚¬ê°í˜•ê³¼ í…ìŠ¤íŠ¸ë¥¼ ê·¸ë¦¬ëŠ” ìž‘ì—…
- íŠ¹ì • ê°ì²´(ìžë™ì°¨,ë²„ìŠ¤ ë“±)ì˜ ìˆ˜ë¥¼ ì´ë¯¸ì§€ì— í‘œì‹œí•¨
"""
def count(founded_classes, im0):
    # founded_classes ë”•ì…”ë„ˆë¦¬ì˜ ì•„ì´í…œì„ ë°˜ë³µí•˜ë©° ê° í´ëž˜ìŠ¤ì˜ ì´ë¦„ê³¼ ê°œìˆ˜ë¥¼ k, vì— ë‹´ìŒ. ë°˜ë³µë¬¸ ë‚´ì—ì„œëŠ” kì˜ ê°’ì— ë”°ë¼ ë‹¤ë¥¸ ë™ìž‘ ìˆ˜í–‰
    for i, (k, v) in enumerate(founded_classes.items()):
        cnt_str = str(k) + ":" + str(v)
        height, width, _ = im0.shape
        # cv2.line(im0, (20,65+ (i*40)), (127,65+ (i*40)), [85,45,255], 30)

        # cv2.rectangle í•¨ìˆ˜ë¥¼ ì‚¬ìš©í•˜ì—¬ ì´ë¯¸ì§€ì— ì‚¬ê°í˜•ì„ ê·¸ë¦¬ê³ 
        # cv2.putText í•¨ìˆ˜ë¥¼ ì‚¬ìš©í•˜ì—¬ ì´ë¯¸ì§€ì— í…ìŠ¤íŠ¸ë¥¼ ê·¸ë¦¼
        if str(k) == 'helmet':
            i = 0
            cv2.rectangle(im0, (width - 190, 45 + (i * 40)), (width, 95 + (i * 40)), [85, 45, 255], -1, cv2.LINE_AA)
            cv2.putText(im0, cnt_str, (width - 190, 75 + (i * 40)), 0, 1, [255, 0, 0], thickness=2,
                        lineType=cv2.LINE_AA)
        elif str(k) == 'head':
            i = 1
            cv2.rectangle(im0, (width - 190, 45 + (i * 40)), (width, 95 + (i * 40)), [85, 45, 255], -1, cv2.LINE_AA)
            cv2.putText(im0, cnt_str, (width - 190, 75 + (i * 40)), 0, 1, [255, 0, 0], thickness=2,
                        lineType=cv2.LINE_AA)
        elif str(k) == 'person':
            i = 2
            cv2.rectangle(im0, (width - 190, 45 + (i * 40)), (width, 95 + (i * 40)), [85, 45, 255], -1, cv2.LINE_AA)
            cv2.putText(im0, cnt_str, (width - 190, 75 + (i * 40)), 0, 1, [255, 0, 0], thickness=2,
                        lineType=cv2.LINE_AA)

"""
2. init_tracker()
- ê°ì²´ ì¶”ì  ì•Œê³ ë¦¬ì¦˜ì¸ DeepSort ì´ˆê¸°í™”
"""
def init_tracker():
    global deepsort
    
    # ì„¤ì • ë¶ˆëŸ¬ì˜¤ê¸°
    cfg_deep = get_config()  # get_config í•¨ìˆ˜ë¥¼ í˜¸ì¶œí•˜ì—¬ cfg_deep ë³€ìˆ˜ì— ì„¤ì •ì„ ë¶ˆëŸ¬ì˜´
    cfg_deep.merge_from_file("deep_sort_pytorch/configs/deep_sort.yaml")  # cfg_deep ì„¤ì • ê°ì²´ì— ~deep_sort.yaml íŒŒì¼ì˜ ì„¤ì •ì„ ë³‘í•©í•¨

    # deepsort ê°ì²´ëŠ” DeepSort í´ëž˜ìŠ¤ì˜ ì¸ìŠ¤í„´ìŠ¤ë¡œ ì´ˆê¸°í™”ë¨
    # ì´ˆê¸°í™”ì— í•„ìš”í•œ ë§¤ê°œë³€ìˆ˜ë“¤ì€ cfg_deep ì„¤ì • ê°ì²´ì—ì„œ ê°€ì ¸ì˜´
    # REID_CKPT : ëª¨ë¸ì˜ ì²´í¬í¬ì¸íŠ¸ ê²½ë¡œ, MAX_DIST : ìµœëŒ€ ê±°ë¦¬ ìž„ê³„ê°’
    deepsort = DeepSort(cfg_deep.DEEPSORT.REID_CKPT,
                        max_dist=cfg_deep.DEEPSORT.MAX_DIST, min_confidence=cfg_deep.DEEPSORT.MIN_CONFIDENCE,
                        nms_max_overlap=cfg_deep.DEEPSORT.NMS_MAX_OVERLAP,
                        max_iou_distance=cfg_deep.DEEPSORT.MAX_IOU_DISTANCE,
                        max_age=cfg_deep.DEEPSORT.MAX_AGE, n_init=cfg_deep.DEEPSORT.N_INIT,
                        nn_budget=cfg_deep.DEEPSORT.NN_BUDGET,
                        use_cuda=True)


"""
3. xyxy_to_xywh(*xyxy), xyxy_to_tlwh(bbox_xyxy)
- ë°”ìš´ë”© ë°•ìŠ¤(bounding box)ì˜ í˜•ì‹ ë³€í™˜
- ë°”ìš´ë”© ë°•ìŠ¤ : ê°ì²´ ê²€ì¶œ(object detection)ì—ì„œ ê°ì²´ì˜ ìœ„ì¹˜ë¥¼ í‘œí˜„í•˜ëŠ” ë° ì‚¬ìš©ë˜ëŠ” ì§ì‚¬ê°í˜•
- ë°”ìš´ë”© ë°•ìŠ¤ëŠ” ë‹¤ì–‘í•œ í˜•ì‹ìœ¼ë¡œ í‘œí˜„ë  ìˆ˜ ìžˆëŠ”ë°, ì£¼ë¡œ ì‚¬ìš©ë˜ëŠ” ë‘ í˜•ì‹ì¸ xyxyì™€ xywh (ë˜ëŠ” tlwh) ì‚¬ì´ì˜ ë³€í™˜ì„ ë‹¤ë£¸
"""
def xyxy_to_xywh(*xyxy):
    """ Calculates the relative bounding box from absolute pixel values. """
    """
    - ìž…ë ¥ : xyxy í˜•ì‹ì˜ ë°”ìš´ë”© ë°•ìŠ¤ (xyxy -ë°•ìŠ¤ì˜ ì™¼ìª½ ìƒë‹¨ ì¢Œí‘œ (x1, y1)ê³¼ ì˜¤ë¥¸ìª½ í•˜ë‹¨ ì¢Œí‘œ (x2, y2))
    - ìž‘ë™ ì›ë¦¬
        Â· ë°”ìš´ë”© ë°•ìŠ¤ì˜ ì™¼ìª½ê³¼ ìƒë‹¨ ì¢Œí‘œë¥¼ ê³„ì‚°í•¨
        Â· ë°”ìš´ë”© ë°•ìˆ˜ì˜ ë„ˆë¹„(bbox_w)ì™€ ë†’ì´(bbox_h)ë¥¼ ê³„ì‚°í•¨
        Â· ì¤‘ì‹¬ì  ì¢Œí‘œ(x_c, y_c) ê³„ì‚°
    - ì¶œë ¥ : xywh í˜•ì‹ì˜ ë°”ìš´ë”© ë°•ìŠ¤ (xywh - ì¤‘ì‹¬ ì¢Œí‘œ(x_c,y_c)ì™€ ë„ˆë¹„ w, ë†’ì´ hë¥¼ ì˜ë¯¸)
    
    """
    bbox_left = min([xyxy[0].item(), xyxy[2].item()])
    bbox_top = min([xyxy[1].item(), xyxy[3].item()])
    bbox_w = abs(xyxy[0].item() - xyxy[2].item())
    bbox_h = abs(xyxy[1].item() - xyxy[3].item())
    x_c = (bbox_left + bbox_w / 2)
    y_c = (bbox_top + bbox_h / 2)
    w = bbox_w
    h = bbox_h
    return x_c, y_c, w, h

def xyxy_to_tlwh(bbox_xyxy):
    """
        - ìž…ë ¥ : xyxy í˜•ì‹ì˜ ë°”ìš´ë”© ë°•ìŠ¤ (xyxy -ë°•ìŠ¤ì˜ ì™¼ìª½ ìƒë‹¨ ì¢Œí‘œ (x1, y1)ê³¼ ì˜¤ë¥¸ìª½ í•˜ë‹¨ ì¢Œí‘œ (x2, y2))
        - ìž‘ë™ ì›ë¦¬
            ìž…ë ¥ëœ ê° ë°”ìš´ë”© ë°•ìŠ¤ì— ëŒ€í•´ :
                Â· ê° ì¢Œí‘œ ê°’ì„ ì •ìˆ˜ë¡œ ë³€í™˜ 
                Â· ìƒë‹¨(top)ê³¼ ì™¼ìª½(left) ì¢Œí‘œë¥¼ ì¶”ì¶œí•¨
                Â· ë„ˆë¹„(w)ì™€ ë†’ì´(h) ê³„ì‚°
                Â· tlwh í˜•ì‹ì˜ ë°”ìš´ë”© ë°•ìŠ¤ë¥¼ ìƒì„±í•˜ê³  ëª©ë¡ì— ì¶”ê°€
        - ì¶œë ¥ : tlwh í˜•ì‹ì˜ ë°”ìš´ë”© ë°•ìŠ¤ (tlwh - ìƒë‹¨ ì¢Œì¸¡ ì¢Œí‘œ(top,left)ì™€ ë„ˆë¹„ w, ë†’ì´ hë¥¼ ì˜ë¯¸)

        """
    tlwh_bboxs = []
    for i, box in enumerate(bbox_xyxy):
        x1, y1, x2, y2 = [int(i) for i in box]
        top = x1
        left = y1
        w = int(x2 - x1)
        h = int(y2 - y1)
        tlwh_obj = [top, left, w, h]
        tlwh_bboxs.append(tlwh_obj)
    return tlwh_bboxs

"""
4. compute_color_for_labels(label)
- ìž…ë ¥ë°›ì€ ë ˆì´ë¸” ê°’ì— ë”°ë¼ íŠ¹ì • ìƒ‰ìƒì„ ë°˜í™˜
- ë ˆì´ë¸” : ì£¼ë¡œ ê°ì²´ ì¸ì‹ì—ì„œ ê°ê°ì˜ ê°ì²´ ì¢…ë¥˜ë¥¼ êµ¬ë¶„í•˜ê¸° ìœ„í•´ ì‚¬ìš©ë˜ëŠ” ì •ìˆ˜ê°’
"""
def compute_color_for_labels(label):
    """
    Simple function that adds fixed color depending on the class
    """
    if label == 0:  # helmet
        color = (222, 82, 175)  # í•‘í¬
    elif label == 1:  # head
        color = (0, 204, 255)  # í•˜ëŠ˜
    elif label == 2:  # person
        color = (85, 45, 255) # ë³´ë¼
    else:
        # ê° ìƒ‰ìƒ ì±„ë„ ê°’ì€ (p * (label ** 2 - label + 1)) % 255ë¥¼ í†µí•´ ê³„ì‚°ë˜ë©° pëŠ” íŒ”ë ˆíŠ¸ì˜ ê° ì›ì†Œ
        color = [int((p * (label ** 2 - label + 1)) % 255) for p in palette]
    return tuple(color)

"""
4. draw_border(img, pt1, pt2, color, thickness, r, d)
- ì´ë¯¸ì§€ì— ë‘¥ê·¼ ëª¨ì„œë¦¬ì˜ ì‚¬ê°í˜• ê²½ê³„ë¥¼ ê·¸ë¦¬ëŠ” í•¨ìˆ˜

# íŒŒë¼ë¯¸í„°
- img : ì´ë¯¸ì§€ ê°ì²´. ì´ ì´ë¯¸ì§€ì— ì‚¬ê°í˜•ì˜ ê²½ê³„ë¥¼ ê·¸ë¦¼
- pt1, pt2: ì‚¬ê°í˜•ì˜ ì™¼ìª½ ìƒë‹¨ ê¼­ì§“ì (pt1)ê³¼ ì˜¤ë¥¸ìª½ í•˜ë‹¨ ê¼­ì§“ì (pt2)ì˜ ì¢Œí‘œ
- color : ì‚¬ê°í˜•ì˜ ìƒ‰ìƒ
- thickness : ì„ ì˜ êµµê¸°
- r : ëª¨ì„œë¦¬ì˜ ë°˜ì§€ë¦„
- d : ëª¨ì„œë¦¬ì˜ ê¸¸ì´ë¥¼ ì¡°ì •í•˜ëŠ” ê°’
"""
def draw_border(img, pt1, pt2, color, thickness, r, d):
    x1, y1 = pt1
    x2, y2 = pt2

    # cv2.line(img, ì‹œìž‘ì , ëì , ìƒ‰ìƒ, ì„ ì˜ êµµê¸°)
    # cv2.ellipse(img, ì¤‘ì‹¬ì , ì¶• ê¸¸ì´, ê°ë„, ì‹œìž‘ ê°ë„, ì¢…ë£Œ ê°ë„, ìƒ‰ìƒ, ì„ ì˜ êµµê¸°)

    # Top left
    cv2.line(img, (x1 + r, y1), (x1 + r + d, y1), color, thickness) # ìˆ˜í‰ì„ 
    cv2.line(img, (x1, y1 + r), (x1, y1 + r + d), color, thickness) # ìˆ˜ì§ì„ 
    cv2.ellipse(img, (x1 + r, y1 + r), (r, r), 180, 0, 90, color, thickness) # ì™¼ìª½ ìƒë‹¨ ëª¨ì„œë¦¬ì— ìœ„ì¹˜í•œ ì›ì˜ 1/4ë¶€ë¶„ì¸ ì›í˜¸ë¥¼ ê·¸ë¦¼
    # Top right
    cv2.line(img, (x2 - r, y1), (x2 - r - d, y1), color, thickness) # ìˆ˜í‰ì„ 
    cv2.line(img, (x2, y1 + r), (x2, y1 + r + d), color, thickness) # ìˆ˜ì§ì„ 
    cv2.ellipse(img, (x2 - r, y1 + r), (r, r), 270, 0, 90, color, thickness) # ì˜¤ë¥¸ìª½ ìƒë‹¨ ëª¨ì„œë¦¬ì— ìœ„ì¹˜í•œ ì›ì˜ 1/4ë¶€ë¶„ì¸ ì›í˜¸ë¥¼ ê·¸ë¦¼
    # Bottom left
    cv2.line(img, (x1 + r, y2), (x1 + r + d, y2), color, thickness) # ìˆ˜í‰ì„ 
    cv2.line(img, (x1, y2 - r), (x1, y2 - r - d), color, thickness) # ìˆ˜ì§ì„ 
    cv2.ellipse(img, (x1 + r, y2 - r), (r, r), 90, 0, 90, color, thickness) # ì™¼ìª½ í•˜ë‹¨ ëª¨ì„œë¦¬ì— ìœ„ì¹˜í•œ ì›ì˜ 1/4ë¶€ë¶„ì¸ ì›í˜¸ë¥¼ ê·¸ë¦¼
    # Bottom right
    cv2.line(img, (x2 - r, y2), (x2 - r - d, y2), color, thickness) # ìˆ˜í‰ì„ 
    cv2.line(img, (x2, y2 - r), (x2, y2 - r - d), color, thickness) # ìˆ˜ì§ì„ 
    cv2.ellipse(img, (x2 - r, y2 - r), (r, r), 0, 0, 90, color, thickness) # ì˜¤ë¥¸ìª½ í•˜ë‹¨ ëª¨ì„œë¦¬ì— ìœ„ì¹˜í•œ ì›ì˜ 1/4ë¶€ë¶„ì¸ ì›í˜¸ë¥¼ ê·¸ë¦¼

    # ì‚¬ê°í˜•ì˜ ìƒë‹¨, ì¤‘ì•™ ë¶€ë¶„
    # cv2.rectangle(img, ì‹œìž‘ì  ì¢Œí‘œ, ì¢…ë£Œì  ì¢Œí‘œ, ìƒ‰ìƒ, ì„ ì˜ êµµê¸°(-1ì€ ì‚¬ê°í˜• ì±„ìš°ê¸°), ì„ ì˜ ìœ í˜•)
    cv2.rectangle(img, (x1 + r, y1), (x2 - r, y2), color, -1, cv2.LINE_AA)
    cv2.rectangle(img, (x1, y1 + r), (x2, y2 - r - d), color, -1, cv2.LINE_AA)

    # ê° ëª¨ì„œë¦¬ì— ìž‘ì€ ì›ì„ ê·¸ë¦¼ (for ë””ìžì¸)
    # cv2.circle(img, ì¤‘ì‹¬ì  ì¢Œí‘œ(ì‚¬ê°í˜•ì˜ ë„¤ ëª¨ì„œë¦¬), ë°˜ì§€ë¦„, ìƒ‰ìƒ, ì„ ì˜ êµµê¸°)
    cv2.circle(img, (x1 + r, y1 + r), 2, color, 12)
    cv2.circle(img, (x2 - r, y1 + r), 2, color, 12)
    cv2.circle(img, (x1 + r, y2 - r), 2, color, 12)
    cv2.circle(img, (x2 - r, y2 - r), 2, color, 12)

    return img

"""
5. UI_box(x, img, color=None, label=None, line_thickness=None)
- ì£¼ì–´ì§„ ì´ë¯¸ì§€ img ìœ„ì— ë°”ìš´ë”© ë°•ìŠ¤ì™€ labelì„ ê·¸ë¦¬ëŠ” ì—­í• 

# íŒŒë¼ë¯¸í„°
- x : ë°”ìš´ë”© ë°•ìŠ¤ì˜ ì¢Œí‘œë¥¼ ë‚˜íƒ€ë‚´ëŠ” ë¦¬ìŠ¤íŠ¸ or íŠœí”Œ (x1, y1, x2, y2)ì˜ í˜•íƒœì—¬ì•¼ í•¨
- img : ë°”ìš´ë”© ë°•ìŠ¤ê°€ ê·¸ë ¤ì§ˆ ì´ë¯¸ì§€
- color : ë°”ìš´ë”© ë°•ìŠ¤ì˜ ìƒ‰ìƒ. ê¸°ë³¸ê°’ì€ ëžœë¤ ìƒ‰ìƒ
- label : ë°”ìš´ë”© ë°•ìŠ¤ ìœ„ì— í‘œì‹œë  í…ìŠ¤íŠ¸ ë ˆì´ë¸”
- line_thickness : ë°”ìš´ë”© ë°•ìŠ¤ì˜ ì„  êµµê¸°. ê¸°ë³¸ê°’ì€ ì´ë¯¸ì§€ì˜ í¬ê¸°ì— ë”°ë¼ ë‹¬ë¼ì§
"""
def UI_box(x, img, color=None, label=None, line_thickness=None):
    # Plots one bounding box on image img
    
    # ì„ ì˜ êµµê¸°ë¥¼ ê³„ì‚°í•˜ê³  ìƒ‰ìƒì´ ì£¼ì–´ì§€ì§€ ì•Šì€ ê²½ìš° ëžœë¤í•œ ìƒ‰ìƒ ìƒì„±
    tl = line_thickness or round(0.002 * (img.shape[0] + img.shape[1]) / 2) + 1  # line/font thickness
    color = color or [random.randint(0, 255) for _ in range(3)]
    
    # ë°”ìš´ë”© ë°•ìŠ¤ì˜ ì¢Œì¸¡ ìƒë‹¨ ì¢Œí‘œ c1ê³¼ ìš°ì¸¡ í•˜ë‹¨ ì¢Œí‘œ c2ë¥¼ ì •ìˆ˜í˜•ìœ¼ë¡œ ë³€í™˜
    c1, c2 = (int(x[0]), int(x[1])), (int(x[2]), int(x[3]))
    
    # cv2.rectangle í•¨ìˆ˜ëŠ” img ì´ë¯¸ì§€ ìœ„ì— ë°”ìš´ë”© ë°•ìŠ¤ë¥¼ ê·¸ë¦¼
    cv2.rectangle(img, c1, c2, color, thickness=tl, lineType=cv2.LINE_AA)
    
    # labelì´ ì£¼ì–´ì§„ ê²½ìš°, labelì˜ í…ìŠ¤íŠ¸ í¬ê¸°ë¥¼ ê³„ì‚°í•˜ê³  labelì˜ ë°°ê²½ ìƒìžë¥¼ ê·¸ë¦¬ë©° cv2.putText í•¨ìˆ˜ë¥¼ ì‚¬ìš©í•˜ì—¬ label í…ìŠ¤íŠ¸ë¥¼ ì´ë¯¸ì§€ì— ì¶”ê°€í•¨
    if label:
        tf = max(tl - 1, 1)  # font thickness
        t_size = cv2.getTextSize(label, 0, fontScale=tl / 3, thickness=tf)[0]

        img = cv2.rectangle(img, (c1[0], c1[1] - t_size[1] - 3), (c1[0] + t_size[0], c1[1] + 3), color, -1, cv2.LINE_AA)

        cv2.putText(img, label, (c1[0], c1[1] - 2), 0, tl / 3, [225, 255, 255], thickness=tf, lineType=cv2.LINE_AA)

"""
6. draw_boxes(img, bbox, names, object_id, identities=None, offset=(0, 0))
- ì£¼ì–´ì§„ ì´ë¯¸ì§€ì— ì—¬ëŸ¬ ê°œì˜ ë°”ìš´ë”© ë°•ìŠ¤ì™€ ê° ë°•ìŠ¤ì— ëŒ€í•œ label, ì•„ì´ë””, ê°ì²´ì˜ ê²½ë¡œ(trail)ë¥¼ ê·¸ë¦¬ëŠ” ì—­í• 
- ì£¼ë¡œ ê°ì²´ ì¶”ì ì—ì„œ ì‚¬ìš©ë¨

# íŒŒë¼ë¯¸í„°
- img : ë°”ìš´ë”© ë°•ìŠ¤ì™€ labelì´ ê·¸ë ¤ì§ˆ ì´ë¯¸ì§€
- bbox : ê° ê°ì²´ì˜ ë°”ìš´ë”© ë°•ìŠ¤ ì¢Œí‘œ ë¦¬ìŠ¤íŠ¸
- names : ê°ì²´ì˜ ì´ë¦„ì„ ë‚˜íƒ€ë‚´ëŠ” ë¬¸ìžì—´ ë¦¬ìŠ¤íŠ¸
- object_id : ê° ë°”ìš´ë”© ë°•ìŠ¤ì— ëŒ€ì‘í•˜ëŠ” ê°ì²´ì˜ ID
- identities : ì¶”ì  ì¤‘ì¸ ê° ê°ì²´ì˜ ID ë¦¬ìŠ¤íŠ¸. ê¸°ë³¸ê°’ì€ None
- offset : ë°”ìš´ë”© ë°•ìŠ¤ì˜ ì¢Œí‘œì— ë”í•´ì§ˆ ì˜¤í”„ì…‹. ê¸°ë³¸ê°’ì€ (0,0)
"""
def draw_boxes(img, bbox, names, object_id, identities=None, offset=(0, 0)):
    # cv2.line(img, line[0], line[1], (46,162,112), 3)

    # ì´ë¯¸ì§€ì˜ ë†’ì´ì™€ ë„ˆë¹„ ì–»ê¸°
    height, width, _ = img.shape

    # data_dequeëŠ” ê° ê°ì²´ì˜ ì´ë™ ê²½ë¡œë¥¼ ì €ìž¥í•¨. ì´ì „ì— ì¶”ì í•˜ë˜ ê°ì²´ê°€ ì‚¬ë¼ì§„ ê²½ìš° data_dequeì—ì„œ í•´ë‹¹ ê°ì²´ì˜ ì •ë³´ë¥¼ ì‚­ì œí•¨
    # remove tracked point from buffer if object is lost
    for key in list(data_deque):
        if key not in identities:
            data_deque.pop(key)

    # ì´ë¯¸ì§€ì— ê·¸ë¦´ ê° ë°”ìš´ë”© ë°•ìŠ¤ì— ëŒ€í•´ ë°•ìŠ¤ì˜ ì¢Œí‘œë¥¼ ê°€ì ¸ì˜¤ê³  í•„ìš”í•˜ë‹¤ë©´ ì˜¤í”„ì…‹ì„ ì ìš©í•¨
    for i, box in enumerate(bbox):
        x1, y1, x2, y2 = [int(i) for i in box]
        x1 += offset[0]
        x2 += offset[0]
        y1 += offset[1]
        y2 += offset[1]

        # ë°”ìš´ë”© ë°•ìŠ¤ì˜ ë°”ë‹¥ ì¤‘ì•™ì ì„ ê³„ì‚°í•¨. ê°ì²´ì˜ ì´ë™ ê²½ë¡œë¥¼ ê·¸ë¦´ ë•Œ ì‚¬ìš©ë¨
        # code to find center of bottom edge
        center = (int((x2 + x1) / 2), int((y2 + y2) / 2))

        # ê°ì²´ì˜ IDë¥¼ ê°€ì ¸ì˜´. ë°”ìš´ë”© ë°•ìŠ¤ì— labelì„ ë¶€ì—¬í•  ë•Œ ì‚¬ìš©ë¨
        # get ID of object
        id = int(identities[i]) if identities is not None else 0

        # ìƒˆë¡œìš´ ê°ì²´ê°€ ë‚˜íƒ€ë‚˜ë©´ í•´ë‹¹ ê°ì²´ì˜ ì´ë™ ê²½ë¡œë¥¼ ì €ìž¥í•  ìƒˆë¡œìš´ dequeë¥¼ ìƒì„±í•¨
        # create new buffer for new object
        if id not in data_deque:
            data_deque[id] = deque(maxlen=64)

        # ê°ì²´ì˜ ìƒ‰ìƒê³¼ ë ˆì´ë¸”ì„ ê³„ì‚°í•¨
        # compute_color_for_labels í•¨ìˆ˜ë¥¼ í†µí•´ì„œ ìƒ‰ìƒì„ ì–»ê³  ê°ì²´ì˜ ì´ë¦„ê³¼ IDë¥¼ ê²°í•©í•˜ì—¬ ë ˆì´ë¸” ìƒì„±
        color = compute_color_for_labels(object_id[i])
        obj_name = names[object_id[i]]
        label = '{}{:d}'.format("", id) + ":" + '%s' % (obj_name)

        # add center to buffer
        # ê³„ì‚°ëœ ì¤‘ì•™ì ì„ dequeì— ì¶”ê°€í•˜ê³  UI_box í•¨ìˆ˜ë¥¼ ì‚¬ìš©í•˜ì—¬ ì´ë¯¸ì§€ì— ë°”ìš´ë”© ë°•ìŠ¤ì™€ labelì„ ê·¸ë¦¼
        data_deque[id].appendleft(center)
        UI_box(box, img, label=label, color=color, line_thickness=2)

        # data_dequeì— ì €ìž¥ëœ ì´ë™ ê²½ë¡œë¥¼ ì‚¬ìš©í•˜ì—¬ ì´ë¯¸ì§€ì— ê°ì²´ì˜ trailì„ ê·¸ë¦¼. trailì˜ ë‘ê»˜ëŠ” ë™ì ìœ¼ë¡œ ê³„ì‚°ë˜ë©° ì´ë™ ê²½ë¡œì˜ ê° ì„ ë¶„ì„ ê·¸ë¦¼
        # draw trail
        for i in range(1, len(data_deque[id])):
            # check if on buffer value is none
            if data_deque[id][i - 1] is None or data_deque[id][i] is None:
                continue
            # generate dynamic thickness of trails
            thickness = int(np.sqrt(64 / float(i + i)) * 1.5)
            # draw trails
            cv2.line(img, data_deque[id][i - 1], data_deque[id][i], color, thickness)
    return img

"""
6. DetectionPredictor(BasePredictor)
- ê°ì²´ íƒì§€ ëª¨ë¸ì˜ ê²°ê³¼ë¥¼ ì „ì²˜ë¦¬ ë° í›„ì²˜ë¦¬í•˜ê³  íƒì§€ëœ ê°ì²´ì— ëŒ€í•œ ì •ë³´ë¥¼ ê¸°ë¡í•˜ê³  ì‹œê°í™”í•¨
"""
class DetectionPredictor(BasePredictor):

    # ì£¼ì–´ì§„ ì´ë¯¸ì§€ì— Annotator ê°ì²´ë¥¼ ì´ˆê¸°í™”í•˜ì—¬ ë°˜í™˜í•¨. AnnotatorëŠ” ì´ë¯¸ì§€ì— ì–´ë…¸í…Œì´ì…˜ì„ ì¶”ê°€í•˜ëŠ” ë„êµ¬ë¡œ ë³´ìž„
    def get_annotator(self, img):
        return Annotator(img, line_width=self.args.line_thickness, example=str(self.model.names))
    
    # ìž…ë ¥ ì´ë¯¸ì§€ ì „ì²˜ë¦¬. ì´ë¯¸ì§€ëŠ” PyTorch í…ì„œë¡œ ë³€í™˜ë˜ê³  ì •ê·œí™”ë¨
    def preprocess(self, img):
        img = torch.from_numpy(img).to(self.model.device)
        img = img.half() if self.model.fp16 else img.float()  # uint8 to fp16/32
        img /= 255  # 0 - 255 to 0.0 - 1.0
        return img

    # ëª¨ë¸ì˜ ì˜ˆì¸¡ ê²°ê³¼ë¥¼ í›„ì²˜ë¦¬í•¨
    # non-maximum suppressionì´ ì ìš©ë˜ì–´ ê° ê°ì²´ì˜ ë°”ìš´ë”© ë°•ìŠ¤ê°€ ì¶”ì¶œë¨. ì˜ í¬ê¸°ê·¸ëŸ° ë‹¤ìŒ ì´ ë°•ìŠ¤ë“¤ì€ ì›ë³¸ ì´ë¯¸ì§€ì— ë§žê²Œ ì¡°ì •ë¨
    def postprocess(self, preds, img, orig_img):
        preds = ops.non_max_suppression(preds,
                                        self.args.conf,
                                        self.args.iou,
                                        agnostic=self.args.agnostic_nms,
                                        max_det=self.args.max_det)

        for i, pred in enumerate(preds):
            shape = orig_img[i].shape if self.webcam else orig_img.shape
            pred[:, :4] = ops.scale_boxes(img.shape[2:], pred[:, :4], shape).round()

        return preds

    # ëª¨ë¸ì˜ ì—ì¸¡ ê²°ê³¼ë¥¼ ì²˜ë¦¬í•˜ì—¬ ê²°ê³¼ë¥¼ ê¸°ë¡í•˜ê³  ì´ë¯¸ì§€ì— ì–´ë…¸í…Œì´ì…˜ì„ ì¶”ê°€í•¨
    # ê° íƒì§€ëœ ê°ì²´ì˜ í´ëž˜ìŠ¤ ë° ìˆ˜ë¥¼ ê³„ì‚°í•˜ê³  ë¡œê·¸ ë¬¸ìžì—´ì— ì¶”ê°€í•¨
    # ì´ë¯¸ì§€ì˜ ê° ê°ì²´ì— ëŒ€í•´ blurring ì²˜ë¦¬ë¥¼ ìˆ˜í–‰í•¨
    # deepsort ì•Œê³ ë¦¬ì¦˜ì„ ì‚¬ìš©í•˜ì—¬ ê°ì²´ì˜ ìœ„ì¹˜ë¥¼ ì¶”ì í•˜ê³  draw_boxes í•¨ìˆ˜ë¥¼ ì‚¬ìš©í•˜ì—¬ ê°ì²´ì˜ ë°”ìš´ë”© ë°•ìŠ¤ë¥¼ ì´ë¯¸ì§€ì— ê·¸ë¦¼
    # ìµœì¢…ì ìœ¼ë¡œ ë¡œê·¸ ë¬¸ìžì—´ì„ ë°˜í™˜í•¨
    def write_results(self, idx, preds, batch):
        p, im, im0 = batch  # ìž…ë ¥ ë°°ì¹˜ì—ì„œ ê° ë³€ìˆ˜ë¥¼ ì¶”ì¶œí•¨ (im : ì›ë³¸ ì´ë¯¸ì§€, im0 : ì²˜ë¦¬ëœ ì´ë¯¸ì§€)
        all_outputs = [] # ëª¨ë“  ì¶œë ¥ì„ ì €ìž¥í•  ë¦¬ìŠ¤íŠ¸ ì´ˆê¸°í™”
        log_string = ""  # ë¡œê·¸ ë¬¸ìžì—´ ì´ˆê¸°í™”
        if len(im.shape) == 3: # ì´ë¯¸ì§€ê°€ ë°°ì¹˜ ì°¨ì›ì„ ê°€ì§€ì§€ ì•Šìœ¼ë©´ ì¶”ê°€í•¨
            im = im[None]  # expand for batch dim
        self.seen += 1 # ì²˜ë¦¬ëœ í”„ë ˆìž„ ìˆ˜ë¥¼ ì¦ê°€ì‹œí‚´
        im0 = im0.copy()  # ì´ë¯¸ì§€ì˜ ë³µì‚¬ë³¸ ìƒì„±
        
        # ì›¹ìº ì´ ì‚¬ìš©ë˜ë©´ ë¡œê·¸ ë¬¸ìžì—´ì— ì¸ë±ìŠ¤ë¥¼ ì¶”ê°€í•˜ê³  í”„ë ˆìž„ ì¹´ìš´íŠ¸ë¥¼ ê°€ì ¸ì˜´
        if self.webcam:  # batch_size >= 1  
            log_string += f'{idx}: ' # ë¡œê·¸ ë¬¸ìžì—´ì— ì¸ë±ìŠ¤ ì¶”ê°€
            frame = self.dataset.count # í”„ë ˆìž„ ì¹´ìš´íŠ¸ ê°€ì ¸ì˜´
        else:  
            frame = getattr(self.dataset, 'frame', 0) # ì›¹ìº ì´ ì•„ë‹Œ ê²½ìš° ë°ì´í„°ì…‹ì˜ í”„ë ˆìž„ ê°’ì„ ê°€ì ¸ì˜´

        # ë°ì´í„° ê²½ë¡œ ì„¤ì •
        self.data_path = p
        save_path = str(self.save_dir / p.name)  # im.jpg # ì´ë¯¸ì§€ ì €ìž¥ ê²½ë¡œ ì„¤ì •
        self.txt_path = str(self.save_dir / 'labels' / p.stem) + ('' if self.dataset.mode == 'image' else f'_{frame}') # í…ìŠ¤íŠ¸ ê²½ë¡œ ì„¤ì •

        log_string += '%gx%g ' % im.shape[2:]  # print string

        self.annotator = self.get_annotator(im0)  # ì–´ë…¸í…Œì´ì…˜ ì„¤ì •
        names = self.model.module.names if hasattr(self.model, 'module') else self.model.names # í´ëž˜ìŠ¤ ì´ë¦„ ê°€ì ¸ì˜¤ê¸°

        # ê°ì²´ íƒì§€ ê²°ê³¼ ì²˜ë¦¬ (ê° íƒì§€ëœ ê°ì²´ì˜ í´ëž˜ìŠ¤ë³„ë¡œ ì¹´ìš´íŠ¸ë¥¼ í•˜ê³  ë¡œê·¸ ë¬¸ìžì—´ì„ ì—…ë°ì´íŠ¸ í•¨)
        det = preds[idx] # í˜„ìž¬ ì¸ë±ìŠ¤ì— í•´ë‹¹í•˜ëŠ” íƒì§€ ê²°ê³¼ ê°€ì ¸ì˜¤ê¸°
        all_outputs.append(det) # íƒì§€ ê²°ê³¼ ì €ìž¥
        if len(det) == 0:
            return log_string  # íƒì§€ëœ ê°ì²´ê°€ ì—†ìœ¼ë©´ ë¡œê·¸ ë¬¸ìžì—´ ë°˜í™˜
        
        # ê°ì²´ ë¸”ëŸ¬ ì²˜ë¦¬ ë° DeepSort ì—…ë°ì´íŠ¸
        for c in det[:, 5].unique():
            n = (det[:, 5] == c).sum()  # detections per class
            class_index = int(c)
            count_of_object = int(n)
            founded_classes = {}
            founded_classes[names[class_index]] = int(n)
            # s += f"{n} {names[int(c)]}{'s' * (n > 1)}, "  # add to string
            count(founded_classes=founded_classes, im0=im0)

            log_string += f"{n} {self.model.names[int(c)]}{'s' * (n > 1)}, "
        # write
        gn = torch.tensor(im0.shape)[[1, 0, 1, 0]]  # normalization gain whwh
        xywh_bboxs = []
        confs = []
        oids = []
        outputs = []
        for *xyxy, conf, cls in reversed(det):
            class_name = names[int(cls)]
            if class_name == 'helmet':
            # Add Object Blurring Code
            # ..................................................................
                crop_obj = im0[int(xyxy[1]):int(xyxy[3]), int(xyxy[0]):int(xyxy[2])]
                blur = cv2.blur(crop_obj, (20, 20))
                im0[int(xyxy[1]):int(xyxy[3]), int(xyxy[0]):int(xyxy[2])] = blur
            # ..................................................................
            
            # ë°”ìš´ë”© ë°•ìŠ¤ ì¢Œí‘œ ë³€í™˜ ë° ì €ìž¥
            x_c, y_c, bbox_w, bbox_h = xyxy_to_xywh(*xyxy)
            xywh_obj = [x_c, y_c, bbox_w, bbox_h]
            xywh_bboxs.append(xywh_obj)
            confs.append([conf.item()])
            oids.append(int(cls))
            
        # DeepSort ì—…ë°ì´íŠ¸
        xywhs = torch.Tensor(xywh_bboxs)
        confss = torch.Tensor(confs)
        outputs = deepsort.update(xywhs, confss, oids, im0)

        # ì¶œë ¥ì´ ìžˆì„ ê²½ì˜¤ draw_boxes í•¨ìˆ˜ë¥¼ í˜¸ì¶œí•˜ì—¬ ì´ë¯¸ì§€ì— ë°•ìŠ¤ë¥¼ ê·¸ë¦¼
        if len(outputs) > 0:
            bbox_xyxy = outputs[:, :4]
            identities = outputs[:, -2]
            object_id = outputs[:, -1]

            draw_boxes(im0, bbox_xyxy, self.model.names, object_id, identities)

        return log_string


@hydra.main(version_base=None, config_path=str(DEFAULT_CONFIG.parent), config_name=DEFAULT_CONFIG.name)
def predict(cfg, model_name="bestv2.pt", source_name="0", show=True):
    init_tracker()
    cfg.model = model_name
    cfg.source = source_name
    cfg.show = show
    predictor = DetectionPredictor(cfg)
    predictor()


if __name__ == "__main__":
    predict()